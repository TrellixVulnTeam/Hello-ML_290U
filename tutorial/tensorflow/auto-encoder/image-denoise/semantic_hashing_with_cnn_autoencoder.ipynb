{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 22:24:44.725461 140628488132416 deprecation.py:506] From /home/guhwanbae/anaconda3/envs/gu-keras/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "height, width, n_channels = input_shape\n",
    "\n",
    "conv_layer = partial(tf.keras.layers.Conv2D,\n",
    "                     kernel_size=(3,3),\n",
    "                     padding='same',\n",
    "                     activation='elu')\n",
    "maxpooling_layer = partial(tf.keras.layers.MaxPool2D,\n",
    "                           pool_size=(2,2),\n",
    "                           strides=(2,2),\n",
    "                           padding='same')\n",
    "upsampling_layer = partial(tf.keras.layers.UpSampling2D,\n",
    "                           size=(2,2))\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(conv_layer(input_shape=input_shape,\n",
    "                     filters=32,\n",
    "                     name='encoder_conv1'))\n",
    "model.add(conv_layer(input_shape=input_shape,\n",
    "                     filters=32,\n",
    "                     name='encoder_conv2'))\n",
    "model.add(maxpooling_layer(name='encoder_maxpooling1'))\n",
    "model.add(tf.keras.layers.Dropout(0.25, name='encoder_dropout1'))\n",
    "model.add(conv_layer(filters=64,\n",
    "                     name='encoder_conv3'))\n",
    "model.add(conv_layer(filters=64,\n",
    "                     name='encoder_conv4'))\n",
    "model.add(maxpooling_layer(name='encoder_maxpooling2'))\n",
    "model.add(tf.keras.layers.Dropout(0.25, name='encoder_dropout2'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(name='flatten'))\n",
    "\n",
    "def binary_relaxation_term(weights, beta=1e-2):\n",
    "    ''' To make sparse and well distributed binary codings. '''\n",
    "    return beta * tf.reduce_sum(tf.linalg.norm(tf.abs(weights) - 1, axis=1))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(30,\n",
    "                                activation='tanh',\n",
    "                                kernel_regularizer=binary_relaxation_term,\n",
    "                                name='latent_vector'))\n",
    "\n",
    "encoder_output_shape = tf.keras.backend.int_shape(model.get_layer('flatten').output)\n",
    "last_conv_shape = tf.keras.backend.int_shape(model.get_layer('encoder_maxpooling2').output)\n",
    "\n",
    "model.add(tf.keras.layers.Dense(encoder_output_shape[1], activation='elu', name='inverse_flatten'))\n",
    "model.add(tf.keras.layers.Reshape((last_conv_shape[1],\n",
    "                                   last_conv_shape[2],\n",
    "                                   last_conv_shape[3]), name='reshape'))\n",
    "\n",
    "model.add(upsampling_layer(name='decoder_upsampling1'))\n",
    "model.add(tf.keras.layers.Dropout(0.25, name='decoder_dropout1'))\n",
    "model.add(conv_layer(filters=64,\n",
    "                     name='decoder_conv1'))\n",
    "model.add(conv_layer(filters=64,\n",
    "                     name='decoder_conv2'))\n",
    "model.add(upsampling_layer(name='decoder_upsampling2'))\n",
    "model.add(tf.keras.layers.Dropout(0.25, name='decoder_dropout2'))\n",
    "model.add(conv_layer(filters=32,\n",
    "                     name='decoder_conv3'))\n",
    "model.add(conv_layer(filters=32,\n",
    "                     name='decoder_conv4'))\n",
    "model.add(conv_layer(filters=1,\n",
    "                     name='outputs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_conv1 (Conv2D)       (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "encoder_conv2 (Conv2D)       (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "encoder_maxpooling1 (MaxPool (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_dropout1 (Dropout)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv3 (Conv2D)       (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "encoder_conv4 (Conv2D)       (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "encoder_maxpooling2 (MaxPool (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_dropout2 (Dropout)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 30)                94110     \n",
      "_________________________________________________________________\n",
      "inverse_flatten (Dense)      (None, 3136)              97216     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_upsampling1 (UpSampl (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_dropout1 (Dropout)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv1 (Conv2D)       (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_conv2 (Conv2D)       (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_upsampling2 (UpSampl (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_dropout2 (Dropout)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv3 (Conv2D)       (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "decoder_conv4 (Conv2D)       (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "outputs (Conv2D)             (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 358,175\n",
      "Trainable params: 358,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(len(y_train), -1).astype(np.float32)\n",
    "X_test = X_test.reshape(len(y_test), -1).astype(np.float32)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train).reshape(-1, height, width, n_channels)\n",
    "X_test = scaler.transform(X_test).reshape(-1, height, width, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(X, noise_level=0.5):\n",
    "    return X + noise_level * np.random.normal(size=X.shape)\n",
    "\n",
    "X_train_noisy = add_gaussian_noise(X_train, noise_level=1.0)\n",
    "X_test_noisy = add_gaussian_noise(X_test, noise_level=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 163.3144 - acc: 0.7962 - val_loss: 158.1862 - val_acc: 0.7996\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 153.2717 - acc: 0.7991 - val_loss: 148.1038 - val_acc: 0.8033\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 26s 433us/sample - loss: 143.1781 - acc: 0.8006 - val_loss: 138.0018 - val_acc: 0.8026\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 133.0715 - acc: 0.8009 - val_loss: 127.8914 - val_acc: 0.8041\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 122.9585 - acc: 0.8012 - val_loss: 117.7761 - val_acc: 0.8034\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 27s 447us/sample - loss: 112.8415 - acc: 0.8016 - val_loss: 107.6581 - val_acc: 0.8049\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 27s 457us/sample - loss: 102.7222 - acc: 0.8019 - val_loss: 97.5384 - val_acc: 0.8058\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 92.6012 - acc: 0.8021 - val_loss: 87.4162 - val_acc: 0.8007\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 82.4793 - acc: 0.8022 - val_loss: 77.2937 - val_acc: 0.8035\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 72.3572 - acc: 0.8024 - val_loss: 67.1715 - val_acc: 0.8030\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 62.2349 - acc: 0.8025 - val_loss: 57.0505 - val_acc: 0.8065\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 52.1132 - acc: 0.8027 - val_loss: 46.9283 - val_acc: 0.8041\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 41.9927 - acc: 0.8028 - val_loss: 36.8096 - val_acc: 0.8064\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 31.8746 - acc: 0.8029 - val_loss: 26.6932 - val_acc: 0.8064\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 21.7604 - acc: 0.8031 - val_loss: 16.5815 - val_acc: 0.8041\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 11.6550 - acc: 0.8031 - val_loss: 6.4841 - val_acc: 0.8045\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 2.2911 - acc: 0.8032 - val_loss: 0.1681 - val_acc: 0.8048\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0721 - acc: 0.8033 - val_loss: 0.0432 - val_acc: 0.8046\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 0.0454 - acc: 0.8034 - val_loss: 0.0405 - val_acc: 0.8056\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 0.0438 - acc: 0.8034 - val_loss: 0.0392 - val_acc: 0.8047\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0426 - acc: 0.8035 - val_loss: 0.0394 - val_acc: 0.8065\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0423 - acc: 0.8037 - val_loss: 0.0386 - val_acc: 0.8043\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0423 - acc: 0.8037 - val_loss: 0.0387 - val_acc: 0.8043\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0425 - acc: 0.8037 - val_loss: 0.0385 - val_acc: 0.8051\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0423 - acc: 0.8038 - val_loss: 0.0388 - val_acc: 0.8057\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 0.0423 - acc: 0.8038 - val_loss: 0.0385 - val_acc: 0.8049\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 28s 459us/sample - loss: 0.0424 - acc: 0.8038 - val_loss: 0.0390 - val_acc: 0.8062\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 27s 456us/sample - loss: 0.0425 - acc: 0.8039 - val_loss: 0.0387 - val_acc: 0.8052\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 0.0425 - acc: 0.8040 - val_loss: 0.0392 - val_acc: 0.8028\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0425 - acc: 0.8040 - val_loss: 0.0388 - val_acc: 0.8055\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0426 - acc: 0.8040 - val_loss: 0.0388 - val_acc: 0.8058\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0425 - acc: 0.8041 - val_loss: 0.0389 - val_acc: 0.8060\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0423 - acc: 0.8041 - val_loss: 0.0387 - val_acc: 0.8054\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0424 - acc: 0.8041 - val_loss: 0.0396 - val_acc: 0.8077\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0422 - acc: 0.8042 - val_loss: 0.0385 - val_acc: 0.8056\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0421 - acc: 0.8043 - val_loss: 0.0384 - val_acc: 0.8054\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0421 - acc: 0.8042 - val_loss: 0.0383 - val_acc: 0.8056\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0417 - acc: 0.8043 - val_loss: 0.0382 - val_acc: 0.8038\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0417 - acc: 0.8043 - val_loss: 0.0381 - val_acc: 0.8059\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0415 - acc: 0.8043 - val_loss: 0.0383 - val_acc: 0.8068\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0414 - acc: 0.8044 - val_loss: 0.0382 - val_acc: 0.8071\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0414 - acc: 0.8044 - val_loss: 0.0377 - val_acc: 0.8051\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0413 - acc: 0.8044 - val_loss: 0.0377 - val_acc: 0.8056\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.0411 - acc: 0.8044 - val_loss: 0.0378 - val_acc: 0.8062\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.0410 - acc: 0.8045 - val_loss: 0.0374 - val_acc: 0.8052\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0410 - acc: 0.8045 - val_loss: 0.0376 - val_acc: 0.8041\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0410 - acc: 0.8045 - val_loss: 0.0374 - val_acc: 0.8049\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0409 - acc: 0.8045 - val_loss: 0.0376 - val_acc: 0.8042\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0409 - acc: 0.8045 - val_loss: 0.0379 - val_acc: 0.8069\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 27s 451us/sample - loss: 0.0408 - acc: 0.8046 - val_loss: 0.0377 - val_acc: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe67dbaaeb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './semantic_hashing_autoencoder.h5'\n",
    "model_saver = tf.keras.callbacks.ModelCheckpoint(filepath=model_path, verbose=0, save_best_only=True)\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0)\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 1024\n",
    "\n",
    "model.fit(x=X_train_noisy, y=X_train,\n",
    "          epochs=n_epochs, batch_size=batch_size,\n",
    "          shuffle=True, validation_data=(X_test_noisy, X_test),\n",
    "          callbacks=[model_saver, early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = model.get_layer('latent_vector').output\n",
    "\n",
    "hash_functor = tf.keras.Model(inputs=model.input,\n",
    "                              outputs=latent_vector)\n",
    "hash_functor.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors_test = hash_functor.predict(X_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_vectors_to_hasing_codes(latent_vectors):\n",
    "    hashing_codes = np.zeros(shape=latent_vectors.shape, dtype='int64')\n",
    "    hashing_codes[latent_vectors <= 0] = 0\n",
    "    hashing_codes[latent_vectors > 0] = 1\n",
    "    return hashing_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hashing_codes_test = latent_vectors_to_hasing_codes(latent_vectors_test)\n",
    "\n",
    "partial_class_idx = np.where(y_test == 8)[0]\n",
    "\n",
    "samples = X_test[partial_class_idx]\n",
    "labels = y_test[partial_class_idx]\n",
    "hashing_codes = hashing_codes_test[partial_class_idx]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for sample, label, code, subplot_idx in zip(samples[:3],\n",
    "                                            labels[:3],\n",
    "                                            hashing_codes[:3], [131, 132, 133]):\n",
    "    plt.subplot(subplot_idx)\n",
    "    plt.title('code = {}'.format(''.join(map(str,code))))\n",
    "    plt.imshow(sample.reshape(28,28))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11242\n"
     ]
    }
   ],
   "source": [
    "def sum_distance(ref, vectors):\n",
    "    return np.sum(np.square(vectors - ref))\n",
    "\n",
    "print(sum_distance(hashing_codes[0], hashing_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0, sum_distance=12395\n",
      "label=1, sum_distance=15287\n",
      "label=2, sum_distance=12332\n",
      "label=3, sum_distance=15824\n",
      "label=4, sum_distance=12351\n",
      "label=5, sum_distance=11815\n",
      "label=6, sum_distance=12302\n",
      "label=7, sum_distance=14097\n",
      "label=8, sum_distance=11242\n",
      "label=9, sum_distance=12602\n"
     ]
    }
   ],
   "source": [
    "# Need to visualize digit-cluster\n",
    "\n",
    "for digit_label in range(10):\n",
    "    other_partial_class_idx = np.where(y_test == digit_label)[0]\n",
    "    other_codes = hashing_codes_test[other_partial_class_idx]\n",
    "    print('label={}, sum_distance={}'.format(digit_label, sum_distance(hashing_codes[0], other_codes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gu-keras",
   "language": "python",
   "name": "gu-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
